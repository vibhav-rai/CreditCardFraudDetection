{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":23498,"sourceType":"datasetVersion","datasetId":310}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-01T05:03:28.284486Z","iopub.execute_input":"2025-09-01T05:03:28.284741Z","iopub.status.idle":"2025-09-01T05:03:30.720626Z","shell.execute_reply.started":"2025-09-01T05:03:28.284718Z","shell.execute_reply":"2025-09-01T05:03:30.719681Z"},"_kg_hide-input":true},"outputs":[{"name":"stdout","text":"/kaggle/input/creditcardfraud/creditcard.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T05:03:30.722328Z","iopub.execute_input":"2025-09-01T05:03:30.723108Z","iopub.status.idle":"2025-09-01T05:03:30.727686Z","shell.execute_reply.started":"2025-09-01T05:03:30.723082Z","shell.execute_reply":"2025-09-01T05:03:30.726541Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"creditcard_v1 = pd.read_csv('/kaggle/input/creditcardfraud/creditcard.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T05:03:30.728850Z","iopub.execute_input":"2025-09-01T05:03:30.729085Z","iopub.status.idle":"2025-09-01T05:03:37.324418Z","shell.execute_reply.started":"2025-09-01T05:03:30.729066Z","shell.execute_reply":"2025-09-01T05:03:37.323252Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"# Steps\n1. Check for nulls and ensure data quality\n2. Split the dataset\n3. Implement ML Algorithms\n4. Cross-Validating the Model\n5. Implement ANN","metadata":{}},{"cell_type":"code","source":"creditcard_v1.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T05:03:37.325532Z","iopub.execute_input":"2025-09-01T05:03:37.325830Z","iopub.status.idle":"2025-09-01T05:03:37.370590Z","shell.execute_reply.started":"2025-09-01T05:03:37.325803Z","shell.execute_reply":"2025-09-01T05:03:37.369466Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"   Time        V1        V2        V3        V4        V5        V6        V7  \\\n0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n\n         V8        V9  ...       V21       V22       V23       V24       V25  \\\n0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n\n        V26       V27       V28  Amount  Class  \n0 -0.189115  0.133558 -0.021053  149.62      0  \n1  0.125895 -0.008983  0.014724    2.69      0  \n2 -0.139097 -0.055353 -0.059752  378.66      0  \n3 -0.221929  0.062723  0.061458  123.50      0  \n4  0.502292  0.219422  0.215153   69.99      0  \n\n[5 rows x 31 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Time</th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>...</th>\n      <th>V21</th>\n      <th>V22</th>\n      <th>V23</th>\n      <th>V24</th>\n      <th>V25</th>\n      <th>V26</th>\n      <th>V27</th>\n      <th>V28</th>\n      <th>Amount</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>-1.359807</td>\n      <td>-0.072781</td>\n      <td>2.536347</td>\n      <td>1.378155</td>\n      <td>-0.338321</td>\n      <td>0.462388</td>\n      <td>0.239599</td>\n      <td>0.098698</td>\n      <td>0.363787</td>\n      <td>...</td>\n      <td>-0.018307</td>\n      <td>0.277838</td>\n      <td>-0.110474</td>\n      <td>0.066928</td>\n      <td>0.128539</td>\n      <td>-0.189115</td>\n      <td>0.133558</td>\n      <td>-0.021053</td>\n      <td>149.62</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>1.191857</td>\n      <td>0.266151</td>\n      <td>0.166480</td>\n      <td>0.448154</td>\n      <td>0.060018</td>\n      <td>-0.082361</td>\n      <td>-0.078803</td>\n      <td>0.085102</td>\n      <td>-0.255425</td>\n      <td>...</td>\n      <td>-0.225775</td>\n      <td>-0.638672</td>\n      <td>0.101288</td>\n      <td>-0.339846</td>\n      <td>0.167170</td>\n      <td>0.125895</td>\n      <td>-0.008983</td>\n      <td>0.014724</td>\n      <td>2.69</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0</td>\n      <td>-1.358354</td>\n      <td>-1.340163</td>\n      <td>1.773209</td>\n      <td>0.379780</td>\n      <td>-0.503198</td>\n      <td>1.800499</td>\n      <td>0.791461</td>\n      <td>0.247676</td>\n      <td>-1.514654</td>\n      <td>...</td>\n      <td>0.247998</td>\n      <td>0.771679</td>\n      <td>0.909412</td>\n      <td>-0.689281</td>\n      <td>-0.327642</td>\n      <td>-0.139097</td>\n      <td>-0.055353</td>\n      <td>-0.059752</td>\n      <td>378.66</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>-0.966272</td>\n      <td>-0.185226</td>\n      <td>1.792993</td>\n      <td>-0.863291</td>\n      <td>-0.010309</td>\n      <td>1.247203</td>\n      <td>0.237609</td>\n      <td>0.377436</td>\n      <td>-1.387024</td>\n      <td>...</td>\n      <td>-0.108300</td>\n      <td>0.005274</td>\n      <td>-0.190321</td>\n      <td>-1.175575</td>\n      <td>0.647376</td>\n      <td>-0.221929</td>\n      <td>0.062723</td>\n      <td>0.061458</td>\n      <td>123.50</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2.0</td>\n      <td>-1.158233</td>\n      <td>0.877737</td>\n      <td>1.548718</td>\n      <td>0.403034</td>\n      <td>-0.407193</td>\n      <td>0.095921</td>\n      <td>0.592941</td>\n      <td>-0.270533</td>\n      <td>0.817739</td>\n      <td>...</td>\n      <td>-0.009431</td>\n      <td>0.798278</td>\n      <td>-0.137458</td>\n      <td>0.141267</td>\n      <td>-0.206010</td>\n      <td>0.502292</td>\n      <td>0.219422</td>\n      <td>0.215153</td>\n      <td>69.99</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 31 columns</p>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"creditcard_v1.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T05:03:37.373430Z","iopub.execute_input":"2025-09-01T05:03:37.374423Z","iopub.status.idle":"2025-09-01T05:03:37.379980Z","shell.execute_reply.started":"2025-09-01T05:03:37.374394Z","shell.execute_reply":"2025-09-01T05:03:37.379039Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"(284807, 31)"},"metadata":{}}],"execution_count":5},{"cell_type":"markdown","source":"# 1. Check for nulls and ensure data quality","metadata":{}},{"cell_type":"code","source":"creditcard_v1.isnull().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T05:03:37.380852Z","iopub.execute_input":"2025-09-01T05:03:37.381169Z","iopub.status.idle":"2025-09-01T05:03:37.441658Z","shell.execute_reply.started":"2025-09-01T05:03:37.381147Z","shell.execute_reply":"2025-09-01T05:03:37.440682Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"Time      0\nV1        0\nV2        0\nV3        0\nV4        0\nV5        0\nV6        0\nV7        0\nV8        0\nV9        0\nV10       0\nV11       0\nV12       0\nV13       0\nV14       0\nV15       0\nV16       0\nV17       0\nV18       0\nV19       0\nV20       0\nV21       0\nV22       0\nV23       0\nV24       0\nV25       0\nV26       0\nV27       0\nV28       0\nAmount    0\nClass     0\ndtype: int64"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"creditcard_v1.describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T05:03:37.442801Z","iopub.execute_input":"2025-09-01T05:03:37.443139Z","iopub.status.idle":"2025-09-01T05:03:37.954477Z","shell.execute_reply.started":"2025-09-01T05:03:37.443107Z","shell.execute_reply":"2025-09-01T05:03:37.953069Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                Time            V1            V2            V3            V4  \\\ncount  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \nmean    94813.859575  1.175161e-15  3.369007e-16 -1.379537e-15  2.094852e-15   \nstd     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \nmin         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \nmax    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n\n                 V5            V6            V7            V8            V9  \\\ncount  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \nmean   1.021879e-15  1.500885e-15 -5.620335e-16  1.149614e-16 -2.426963e-15   \nstd    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \nmin   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \nmax    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n\n       ...           V21           V22           V23           V24  \\\ncount  ...  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \nmean   ...  1.596686e-16 -3.576577e-16  2.650499e-16  4.472317e-15   \nstd    ...  7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \nmin    ... -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n25%    ... -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n50%    ... -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n75%    ...  1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \nmax    ...  2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n\n                V25           V26           V27           V28         Amount  \\\ncount  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \nmean   5.109395e-16  1.686100e-15 -3.662399e-16 -1.225457e-16      88.349619   \nstd    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \nmin   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \nmax    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n\n               Class  \ncount  284807.000000  \nmean        0.001727  \nstd         0.041527  \nmin         0.000000  \n25%         0.000000  \n50%         0.000000  \n75%         0.000000  \nmax         1.000000  \n\n[8 rows x 31 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Time</th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>...</th>\n      <th>V21</th>\n      <th>V22</th>\n      <th>V23</th>\n      <th>V24</th>\n      <th>V25</th>\n      <th>V26</th>\n      <th>V27</th>\n      <th>V28</th>\n      <th>Amount</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>284807.000000</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>...</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>2.848070e+05</td>\n      <td>284807.000000</td>\n      <td>284807.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>94813.859575</td>\n      <td>1.175161e-15</td>\n      <td>3.369007e-16</td>\n      <td>-1.379537e-15</td>\n      <td>2.094852e-15</td>\n      <td>1.021879e-15</td>\n      <td>1.500885e-15</td>\n      <td>-5.620335e-16</td>\n      <td>1.149614e-16</td>\n      <td>-2.426963e-15</td>\n      <td>...</td>\n      <td>1.596686e-16</td>\n      <td>-3.576577e-16</td>\n      <td>2.650499e-16</td>\n      <td>4.472317e-15</td>\n      <td>5.109395e-16</td>\n      <td>1.686100e-15</td>\n      <td>-3.662399e-16</td>\n      <td>-1.225457e-16</td>\n      <td>88.349619</td>\n      <td>0.001727</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>47488.145955</td>\n      <td>1.958696e+00</td>\n      <td>1.651309e+00</td>\n      <td>1.516255e+00</td>\n      <td>1.415869e+00</td>\n      <td>1.380247e+00</td>\n      <td>1.332271e+00</td>\n      <td>1.237094e+00</td>\n      <td>1.194353e+00</td>\n      <td>1.098632e+00</td>\n      <td>...</td>\n      <td>7.345240e-01</td>\n      <td>7.257016e-01</td>\n      <td>6.244603e-01</td>\n      <td>6.056471e-01</td>\n      <td>5.212781e-01</td>\n      <td>4.822270e-01</td>\n      <td>4.036325e-01</td>\n      <td>3.300833e-01</td>\n      <td>250.120109</td>\n      <td>0.041527</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>-5.640751e+01</td>\n      <td>-7.271573e+01</td>\n      <td>-4.832559e+01</td>\n      <td>-5.683171e+00</td>\n      <td>-1.137433e+02</td>\n      <td>-2.616051e+01</td>\n      <td>-4.355724e+01</td>\n      <td>-7.321672e+01</td>\n      <td>-1.343407e+01</td>\n      <td>...</td>\n      <td>-3.483038e+01</td>\n      <td>-1.093314e+01</td>\n      <td>-4.480774e+01</td>\n      <td>-2.836627e+00</td>\n      <td>-1.029540e+01</td>\n      <td>-2.604551e+00</td>\n      <td>-2.256568e+01</td>\n      <td>-1.543008e+01</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>54201.500000</td>\n      <td>-9.203734e-01</td>\n      <td>-5.985499e-01</td>\n      <td>-8.903648e-01</td>\n      <td>-8.486401e-01</td>\n      <td>-6.915971e-01</td>\n      <td>-7.682956e-01</td>\n      <td>-5.540759e-01</td>\n      <td>-2.086297e-01</td>\n      <td>-6.430976e-01</td>\n      <td>...</td>\n      <td>-2.283949e-01</td>\n      <td>-5.423504e-01</td>\n      <td>-1.618463e-01</td>\n      <td>-3.545861e-01</td>\n      <td>-3.171451e-01</td>\n      <td>-3.269839e-01</td>\n      <td>-7.083953e-02</td>\n      <td>-5.295979e-02</td>\n      <td>5.600000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>84692.000000</td>\n      <td>1.810880e-02</td>\n      <td>6.548556e-02</td>\n      <td>1.798463e-01</td>\n      <td>-1.984653e-02</td>\n      <td>-5.433583e-02</td>\n      <td>-2.741871e-01</td>\n      <td>4.010308e-02</td>\n      <td>2.235804e-02</td>\n      <td>-5.142873e-02</td>\n      <td>...</td>\n      <td>-2.945017e-02</td>\n      <td>6.781943e-03</td>\n      <td>-1.119293e-02</td>\n      <td>4.097606e-02</td>\n      <td>1.659350e-02</td>\n      <td>-5.213911e-02</td>\n      <td>1.342146e-03</td>\n      <td>1.124383e-02</td>\n      <td>22.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>139320.500000</td>\n      <td>1.315642e+00</td>\n      <td>8.037239e-01</td>\n      <td>1.027196e+00</td>\n      <td>7.433413e-01</td>\n      <td>6.119264e-01</td>\n      <td>3.985649e-01</td>\n      <td>5.704361e-01</td>\n      <td>3.273459e-01</td>\n      <td>5.971390e-01</td>\n      <td>...</td>\n      <td>1.863772e-01</td>\n      <td>5.285536e-01</td>\n      <td>1.476421e-01</td>\n      <td>4.395266e-01</td>\n      <td>3.507156e-01</td>\n      <td>2.409522e-01</td>\n      <td>9.104512e-02</td>\n      <td>7.827995e-02</td>\n      <td>77.165000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>172792.000000</td>\n      <td>2.454930e+00</td>\n      <td>2.205773e+01</td>\n      <td>9.382558e+00</td>\n      <td>1.687534e+01</td>\n      <td>3.480167e+01</td>\n      <td>7.330163e+01</td>\n      <td>1.205895e+02</td>\n      <td>2.000721e+01</td>\n      <td>1.559499e+01</td>\n      <td>...</td>\n      <td>2.720284e+01</td>\n      <td>1.050309e+01</td>\n      <td>2.252841e+01</td>\n      <td>4.584549e+00</td>\n      <td>7.519589e+00</td>\n      <td>3.517346e+00</td>\n      <td>3.161220e+01</td>\n      <td>3.384781e+01</td>\n      <td>25691.160000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 31 columns</p>\n</div>"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"pip install scikit-learn==1.3.2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T05:03:37.956134Z","iopub.execute_input":"2025-09-01T05:03:37.956482Z","iopub.status.idle":"2025-09-01T05:03:47.490435Z","shell.execute_reply.started":"2025-09-01T05:03:37.956443Z","shell.execute_reply":"2025-09-01T05:03:47.489274Z"}},"outputs":[{"name":"stdout","text":"Collecting scikit-learn==1.3.2\n  Downloading scikit_learn-1.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\nRequirement already satisfied: numpy<2.0,>=1.17.3 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.3.2) (1.26.4)\nRequirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.3.2) (1.15.3)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.3.2) (1.5.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.3.2) (3.6.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<2.0,>=1.17.3->scikit-learn==1.3.2) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<2.0,>=1.17.3->scikit-learn==1.3.2) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<2.0,>=1.17.3->scikit-learn==1.3.2) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<2.0,>=1.17.3->scikit-learn==1.3.2) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<2.0,>=1.17.3->scikit-learn==1.3.2) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<2.0,>=1.17.3->scikit-learn==1.3.2) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.0,>=1.17.3->scikit-learn==1.3.2) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.0,>=1.17.3->scikit-learn==1.3.2) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<2.0,>=1.17.3->scikit-learn==1.3.2) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<2.0,>=1.17.3->scikit-learn==1.3.2) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<2.0,>=1.17.3->scikit-learn==1.3.2) (2024.2.0)\nDownloading scikit_learn-1.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m72.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hInstalling collected packages: scikit-learn\n  Attempting uninstall: scikit-learn\n    Found existing installation: scikit-learn 1.2.2\n    Uninstalling scikit-learn-1.2.2:\n      Successfully uninstalled scikit-learn-1.2.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed scikit-learn-1.3.2\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"# 2. Split the dataset","metadata":{}},{"cell_type":"code","source":"# Import libraries and split the dataset\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom imblearn.pipeline import Pipeline as ImbPipeline\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.metrics import average_precision_score\n\nX = creditcard_v1.drop(['Class'], axis = 1)\ny = creditcard_v1['Class']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T05:03:47.491833Z","iopub.execute_input":"2025-09-01T05:03:47.492750Z","iopub.status.idle":"2025-09-01T05:03:50.137575Z","shell.execute_reply.started":"2025-09-01T05:03:47.492713Z","shell.execute_reply":"2025-09-01T05:03:50.136370Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"# 3. Implement ML Algorithms","metadata":{}},{"cell_type":"code","source":"# random_forest_pipeline = ImbPipeline([\n#     ('preprocessor', StandardScaler()),\n#     ('smote', SMOTE(random_state = 42)),\n#     ('classifier', RandomForestClassifier(random_state = 42))\n# ])\n\n# param_grid = {\n#     'classifier__n_estimators': [50, 100],\n#     'classifier__max_depth': [None, 5, 10]\n# }\n\n# rf_random_search = RandomizedSearchCV(random_forest_pipeline, param_grid, cv = 3, error_score = 'raise', scoring = 'average_precision', verbose = 2, n_iter = 20)\n# rf_random_search.fit(X_train, y_train)\n\n# print(\"Best Score :\", rf_random_search.best_score_)\n# print(\"Best Params :\", rf_random_search.best_params_)\n\n# best_model = rf_random_search.best_estimator_\n# y_pred = best_model.predict(X_test)\n\n# print(\"AUPRC :\", average_precision_score(y_test, y_pred))\n\n# Commented since the algo takes a lot of time.\n# Parameters were:\n# Best Score : 0.818903132579916\n# Best Params : {'classifier__n_estimators': 100, 'classifier__max_depth': None}\n# AUPRC : 0.743948963051391","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T05:03:50.139031Z","iopub.execute_input":"2025-09-01T05:03:50.139599Z","iopub.status.idle":"2025-09-01T05:03:50.144952Z","shell.execute_reply.started":"2025-09-01T05:03:50.139565Z","shell.execute_reply":"2025-09-01T05:03:50.143748Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# Ratio of Non Fraud to Fraud for scale_pos_weight\ncounts = creditcard_v1['Class'].value_counts()\nnon_fraud_cnt = counts[0]\nfraud_cnt = counts[1]\nscale_pos_weight = non_fraud_cnt/fraud_cnt\nprint(\"Non Fraud: \", non_fraud_cnt)\nprint(\"Fraud: \", fraud_cnt)\nprint(scale_pos_weight)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T05:03:50.146797Z","iopub.execute_input":"2025-09-01T05:03:50.147535Z","iopub.status.idle":"2025-09-01T05:03:50.207009Z","shell.execute_reply.started":"2025-09-01T05:03:50.147487Z","shell.execute_reply":"2025-09-01T05:03:50.205934Z"}},"outputs":[{"name":"stdout","text":"Non Fraud:  284315\nFraud:  492\n577.8760162601626\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"xgboost_classifier = Pipeline([\n    ('preprocessor', StandardScaler()),\n    ('classifier', XGBClassifier(random_state = 42, scale_pos_weight = scale_pos_weight, eval_metric = 'aucpr'))\n])\n\n\nparam_grid = {\n    'classifier__max_depth': [5,7,10],\n    'classifier__n_estimators': [50, 100, 200],\n    'classifier__learning_rate': [0.01, 0.05, 0.1],\n}\n\nxgb_random_search = RandomizedSearchCV(xgboost_classifier, param_grid, cv = 3, error_score = 'raise', scoring = 'average_precision', verbose = 2, n_iter = 20, n_jobs = -1)\nxgb_random_search.fit(X_train, y_train)\n\nprint(\"Best Score :\", xgb_random_search.best_score_)\nprint(\"Best Params :\", xgb_random_search.best_params_)\n\nxgb_best_model = xgb_random_search.best_estimator_\ny_pred = xgb_random_search.predict(X_test)\n\nprint(\"AUPRC :\", average_precision_score(y_test, y_pred))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T05:03:50.208109Z","iopub.execute_input":"2025-09-01T05:03:50.208351Z","iopub.status.idle":"2025-09-01T05:05:36.452195Z","shell.execute_reply.started":"2025-09-01T05:03:50.208333Z","shell.execute_reply":"2025-09-01T05:05:36.451437Z"}},"outputs":[{"name":"stdout","text":"Fitting 3 folds for each of 20 candidates, totalling 60 fits\nBest Score : 0.835069254508357\nBest Params : {'classifier__n_estimators': 200, 'classifier__max_depth': 5, 'classifier__learning_rate': 0.1}\nAUPRC : 0.7530220854454175\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"# 4. Cross-Validating the Model","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\n\ncv_scores = cross_val_score(xgb_best_model, X_train, y_train, cv = 5, scoring = 'average_precision')\n\nprint('CV AUPRC Score :', cv_scores.mean())\nprint('CV AUPRC Std :', cv_scores.std())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T05:05:36.454581Z","iopub.execute_input":"2025-09-01T05:05:36.455458Z","iopub.status.idle":"2025-09-01T05:05:51.535806Z","shell.execute_reply.started":"2025-09-01T05:05:36.455427Z","shell.execute_reply":"2025-09-01T05:05:51.534539Z"}},"outputs":[{"name":"stdout","text":"CV AUPRC Score : 0.83311346536775\nCV AUPRC Std : 0.038103678746507955\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"# 5. Implement ANN","metadata":{}},{"cell_type":"code","source":"pip install imbalanced-learn","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T05:40:02.136500Z","iopub.execute_input":"2025-09-01T05:40:02.136999Z","iopub.status.idle":"2025-09-01T05:40:06.340234Z","shell.execute_reply.started":"2025-09-01T05:40:02.136970Z","shell.execute_reply":"2025-09-01T05:40:06.338997Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.11/dist-packages (0.13.0)\nRequirement already satisfied: numpy<3,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (1.26.4)\nRequirement already satisfied: scipy<2,>=1.10.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (1.15.3)\nRequirement already satisfied: scikit-learn<2,>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (1.3.2)\nRequirement already satisfied: sklearn-compat<1,>=0.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (0.1.3)\nRequirement already satisfied: joblib<2,>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (1.5.1)\nRequirement already satisfied: threadpoolctl<4,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (3.6.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.24.3->imbalanced-learn) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.24.3->imbalanced-learn) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.24.3->imbalanced-learn) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.24.3->imbalanced-learn) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.24.3->imbalanced-learn) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.24.3->imbalanced-learn) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3,>=1.24.3->imbalanced-learn) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3,>=1.24.3->imbalanced-learn) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3,>=1.24.3->imbalanced-learn) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3,>=1.24.3->imbalanced-learn) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3,>=1.24.3->imbalanced-learn) (2024.2.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom imblearn.over_sampling import SMOTE\nimport numpy as np\n\nX = creditcard_v1.drop(['Class'], axis = 1)\ny = creditcard_v1['Class']\n\n# First split into train+temp and test\nX_train, X_temp, y_train, y_temp = train_test_split(\n    X, y, test_size=0.3, stratify=y, random_state=42\n)\n\n# Then split temp into validation and test\nX_val, X_test, y_val, y_test = train_test_split(\n    X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42\n)\n\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_val   = scaler.transform(X_val)\nX_test  = scaler.transform(X_test)\n\nsmote = SMOTE(random_state=42)\nX_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n\nmodel = Sequential()\n\nmodel.add(Dense(units = 32, activation = 'relu', input_shape = (X_train.shape[1],)))\nmodel.add(Dense(units = 16, activation = 'relu'))\nmodel.add(Dense(units = 8, activation = 'relu'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(units = 1, activation = 'sigmoid'))\n\nmodel.compile(optimizer='adam',\n              loss = 'binary_crossentropy',\n              metrics = [tf.keras.metrics.AUC(curve = 'PR', name = 'auprc')]\n             )\n\nearly_stop = EarlyStopping(\n    monitor='val_auprc',    # metric to track (use 'val_loss' if auprc not in metrics)\n    patience=5,             # stop if no improvement for 5 epochs\n    mode='max',\n    restore_best_weights=True\n)\n\nhistory = model.fit(\n    X_train_res, y_train_res,\n    validation_data=(X_val, y_val),\n    batch_size=50,\n    epochs=50,\n    callbacks=[early_stop],\n    verbose=2\n)\n\ntest_auprc = model.evaluate(X_test, y_test)\nprint(\"Test AUPRC:\", test_auprc)\n\ny_pred_probs = model.predict(X_test)\ny_pred = (y_pred_probs > 0.5).astype(int)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T05:57:27.305870Z","iopub.execute_input":"2025-09-01T05:57:27.307079Z","iopub.status.idle":"2025-09-01T06:02:41.149492Z","shell.execute_reply.started":"2025-09-01T05:57:27.307033Z","shell.execute_reply":"2025-09-01T06:02:41.148414Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/50\n7961/7961 - 22s - 3ms/step - auprc: 0.9985 - loss: 0.0424 - val_auprc: 0.4910 - val_loss: 0.0231\nEpoch 2/50\n7961/7961 - 20s - 3ms/step - auprc: 0.9994 - loss: 0.0130 - val_auprc: 0.5462 - val_loss: 0.0198\nEpoch 3/50\n7961/7961 - 20s - 2ms/step - auprc: 0.9995 - loss: 0.0110 - val_auprc: 0.5665 - val_loss: 0.0220\nEpoch 4/50\n7961/7961 - 19s - 2ms/step - auprc: 0.9996 - loss: 0.0099 - val_auprc: 0.5942 - val_loss: 0.0218\nEpoch 5/50\n7961/7961 - 20s - 3ms/step - auprc: 0.9996 - loss: 0.0094 - val_auprc: 0.5718 - val_loss: 0.0238\nEpoch 6/50\n7961/7961 - 20s - 2ms/step - auprc: 0.9997 - loss: 0.0092 - val_auprc: 0.6360 - val_loss: 0.0235\nEpoch 7/50\n7961/7961 - 19s - 2ms/step - auprc: 0.9997 - loss: 0.0086 - val_auprc: 0.6176 - val_loss: 0.0253\nEpoch 8/50\n7961/7961 - 20s - 2ms/step - auprc: 0.9997 - loss: 0.0083 - val_auprc: 0.6074 - val_loss: 0.0240\nEpoch 9/50\n7961/7961 - 18s - 2ms/step - auprc: 0.9997 - loss: 0.0080 - val_auprc: 0.5904 - val_loss: 0.0277\nEpoch 10/50\n7961/7961 - 18s - 2ms/step - auprc: 0.9998 - loss: 0.0076 - val_auprc: 0.5871 - val_loss: 0.0282\nEpoch 11/50\n7961/7961 - 19s - 2ms/step - auprc: 0.9998 - loss: 0.0080 - val_auprc: 0.6917 - val_loss: 0.0274\nEpoch 12/50\n7961/7961 - 19s - 2ms/step - auprc: 0.9998 - loss: 0.0076 - val_auprc: 0.5991 - val_loss: 0.0279\nEpoch 13/50\n7961/7961 - 19s - 2ms/step - auprc: 0.9998 - loss: 0.0075 - val_auprc: 0.6846 - val_loss: 0.0268\nEpoch 14/50\n7961/7961 - 18s - 2ms/step - auprc: 0.9998 - loss: 0.0075 - val_auprc: 0.6375 - val_loss: 0.0284\nEpoch 15/50\n7961/7961 - 19s - 2ms/step - auprc: 0.9998 - loss: 0.0074 - val_auprc: 0.6546 - val_loss: 0.0285\nEpoch 16/50\n7961/7961 - 18s - 2ms/step - auprc: 0.9998 - loss: 0.0073 - val_auprc: 0.6258 - val_loss: 0.0313\n\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - auprc: 0.7465 - loss: 0.0206\nTest AUPRC: [0.02734888717532158, 0.7104237079620361]\n\u001b[1m1336/1336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"# XGBoost had a better AUPRC while being computationally inexpensive than ANN.","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-01T06:40:44.323502Z","iopub.execute_input":"2025-09-01T06:40:44.323914Z","iopub.status.idle":"2025-09-01T06:40:44.329265Z","shell.execute_reply.started":"2025-09-01T06:40:44.323886Z","shell.execute_reply":"2025-09-01T06:40:44.328120Z"}},"outputs":[],"execution_count":36}]}